# Speech-Emotion-Recognition


There are 4 scripts here LSTM_SheMO, LSTM_EmoDB,  LSTM_Combined, and LSTM_Cross_Predict 

Also, you will need to download all the functions as well as there are two dataset one is EmoDB which gets downloaded onto internal Matlab folder 


As for the there dataset , you will need to download ShEMO dataset from this link. There are more than 100 files so it wasâ€™t practical to upload it to GitHub. Here is the link to that:

[https://unisydneyedu-my.sharepoint.com/personal/aall0481_uni_sydney_edu_au/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Faall0481%5Funi%5Fsydney%5Fedu%5Fau%2FDocuments%2FShEMO&ga=1](https://unisydneyedu-my.sharepoint.com/:f:/g/personal/aall0481_uni_sydney_edu_au/EhIiYtclLq5Eo_UL89qL7J0B9bci4Vc_YiW6X5GlNwwadw?e=BZe2ew)

There are two options to run this:

Option 1:


When you download the codes and the above dataset, run this you will need to run them in a below in either order:

LSTM_SheMO 

 LSTM_EmoDB  

And the you can run 

LSTM_Combined 

Followed by 

LSTM_Cross_Predict 

Because files are generate by each of the scripts that are used in subsquance

Or option 2:

You can download the work_space files from this OneDrive link below because GitHub has a size limit  and just download the codes and test on the outputs that I worked on which will save sometimes.

Here is the link to the work-space files:

https://unisydneyedu-my.sharepoint.com/personal/aall0481_uni_sydney_edu_au/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Faall0481%5Funi%5Fsydney%5Fedu%5Fau%2FDocuments%2FSpeech%20Emotion%20Recognition%20work%5Fspace%5Ffiles&ga=1
